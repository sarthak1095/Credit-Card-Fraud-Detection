# -*- coding: utf-8 -*-
"""self_Credit card fraud detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/120Oot8nfhANk-xrD3LgZ68-1m0lrRP20

# Part 1: Data preprocessing

Dataset link: https://www.kaggle.com/mlg-ulb/creditcardfraud?select=creditcard.csv

## Importing the libraries and the dataset
"""

import numpy as np                 # Importing the numpy library for numerical operations
import pandas as pd                # Importing the pandas library for data manipulation and analysis
import matplotlib.pyplot as plt    # Importing the matplotlib library for data visualization
import seaborn as sns              # Importing the seaborn library for advanced data visualization

! pip install -q kaggle    # Installing the Kaggle package using pip

! mkdir ~/.kaggle                          # Creating a directory named ".kaggle" in the user's home directory
! cp kaggle.json ~/.kaggle/                # Copying the file "kaggle.json" to the ".kaggle" directory
! chmod 600 /root/.kaggle/kaggle.json      # Setting the permissions of the "kaggle.json" file to read and write only for the owner
! kaggle datasets download -d mlg-ulb/creditcardfraud   # Downloading the dataset with the specified Kaggle dataset ID

! unzip -q /content/creditcardfraud.zip    # Unzipping the file "creditcardfraud.zip" in the "/content" directory

"""## Data Exploration"""

# Read the CSV file
dataset = pd.read_csv("/content/creditcard.csv")

# Display the first few rows of the dataset
dataset.head()

# Display the shape of the dataset
# The shape attribute returns a tuple representing the dimensions of the dataset (rows, columns)
print("Dataset shape:", dataset.shape)

# Display the columns of the dataset
# The columns attribute returns a pandas Index object representing the column names
column_names = dataset.columns
print("Column names:", column_names)

# Display information about the dataset
# The info() method provides a summary of the dataset including column names, data types, and non-null values
dataset.info()

# Generate descriptive statistics of the dataset
# The describe() method provides summary statistics of the numerical columns in the dataset
# This includes count, mean, standard deviation, minimum, 25th percentile, median, 75th percentile, and maximum values
dataset.describe()

"""## Dealing with missing values"""

# Check for missing values in the dataset
# The isnull() function returns a DataFrame of boolean values indicating if each element is null or not
# The values attribute retrieves the underlying NumPy array from the DataFrame
# The any() method checks if there are any True values in the array, indicating the presence of missing values
missing_values = dataset.isnull().values.any()

if missing_values:
    print("The dataset contains missing values.")
else:
    print("The dataset does not contain missing values.")

# Calculate the total number of missing values in the dataset
# The sum() method calculates the sum of all True values in the array, which represents the count of missing values
missing_values_count = dataset.isnull().values.sum()

print("Total missing values in the dataset:", missing_values_count)

"""## Encoding categorical data"""

# Select columns of object data type from the dataset
# The select_dtypes(include="object") function selects columns with object (string) data type
# The columns attribute retrieves the column names as a pandas Index object
object_columns = dataset.select_dtypes(include="object").columns

print("Object columns in the dataset:")
print(object_columns)

# Calculate the number of columns with object data type in the dataset
# The select_dtypes(include="object") function selects columns with object (string) data type
# The columns attribute retrieves the column names as a pandas Index object
# The len() function calculates the number of columns in the Index object
object_columns_count = len(dataset.select_dtypes(include="object").columns)

print("Number of object columns in the dataset:", object_columns_count)

"""## Countplot"""

# Set the figure size
plt.figure(figsize=(6, 4))

# Create the countplot
sns.countplot(data=dataset, x='Class')

# Add labels and title
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Distribution of Classes')

# Rotate x-axis labels if needed
plt.xticks(rotation=0)

# Display the plot
plt.tight_layout()
plt.show()

# non fraud transactions
(dataset.Class == 0).sum()

# fraud transactions
(dataset.Class == 1).sum()

"""## Correlation matrix and heatmap"""

# Create a new dataset by dropping the "Class" column
# The drop(columns="Class") function drops the specified column from the dataset
# The result is stored in the new dataset, dataset_2
dataset_2 = dataset.drop(columns="Class")

# Create a new dataset by dropping the "Class" column
dataset_2 = dataset.drop(columns="Class")

# Calculate the correlation between dataset_2 columns and the "Class" column
correlation = dataset_2.corrwith(dataset['Class'])

# Plot the correlation values as a bar chart
# figsize=(16, 9) sets the size of the figure
# title='correlated with class' sets the title of the plot
# grid=True displays grid lines in the plot
correlation.plot.bar(figsize=(16, 9), title='Correlated with Class', grid=True)

# Display the plot
plt.show()

# Calculate the correlation matrix of the dataset
# The corr() function calculates the pairwise correlation between columns in the dataset
# The result is stored in the variable 'corr' as a correlation matrix
corr = dataset.corr()

# Calculate the correlation matrix of the dataset
corr = dataset.corr()

# Set the figure size for the heatmap plot
plt.figure(figsize=(16, 9))

# Create a heatmap plot of the correlation matrix
# The heatmap is created using seaborn's heatmap function
# The 'annot=True' parameter displays the correlation values on the heatmap
# The 'linewidths=2' parameter sets the width of the lines separating the cells in the heatmap
ax = sns.heatmap(corr, annot=True, linewidths=2)

# Display the heatmap plot
plt.show()

"""## Splitting the dataset"""

x = dataset.drop(columns = 'Class')
y = dataset['Class']

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
# The train_test_split() function splits the data into random train and test subsets
# The 'x' and 'y' variables represent the input features and target variable, respectively
# The 'test_size=0.2' parameter specifies that 20% of the data will be used for testing
# The 'random_state=0' parameter sets the random seed for reproducibility
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

print(x_train.shape)

print(x_test.shape)

print(y_train.shape)

print(y_test.shape)

"""## Feature scaling"""

from sklearn.preprocessing import StandardScaler

# Create an instance of the StandardScaler class
# The StandardScaler class is used to standardize the features by removing the mean and scaling to unit variance
sc = StandardScaler()

# Standardize the training data
# The fit_transform() method computes the mean and standard deviation of the features in the training set
# It then standardizes the training data by subtracting the mean and dividing by the standard deviation
x_train = sc.fit_transform(x_train)

# Standardize the testing data
# The transform() method uses the mean and standard deviation computed from the training set
# It applies the same standardization to the testing data, ensuring consistency with the training data
x_test = sc.transform(x_test)

print(x_train)

print(x_test)

"""# Part 2: Building the model

## 1) Logistic regression
"""

# Importing the LogisticRegression class from the linear_model module in the sklearn library
from sklearn.linear_model import LogisticRegression

# Creating an instance of the LogisticRegression classifier
classifier_LR = LogisticRegression()

# Training the classifier using the training data
# x_train is the input features or independent variables
# y_train is the target variable or dependent variable
classifier_LR.fit(x_train, y_train)

# Generating predictions using the trained Logistic Regression classifier on the test data
# x_test represents the input features of the test data
y_pred = classifier_LR.predict(x_test)

# Importing the required metrics from the sklearn library
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score

# Calculating the accuracy score by comparing the true labels (y_test) with the predicted labels (y_pred)
acc_LR = accuracy_score(y_test, y_pred)

# Calculating the F1 score by comparing the true labels (y_test) with the predicted labels (y_pred)
f1_LR = f1_score(y_test, y_pred)

# Calculating the precision score by comparing the true labels (y_test) with the predicted labels (y_pred)
pre_LR = precision_score(y_test, y_pred)

# Calculating the recall score by comparing the true labels (y_test) with the predicted labels (y_pred)
rec_LR = recall_score(y_test, y_pred)

# Creating a pandas DataFrame to store the evaluation results
# The DataFrame has one row containing the model name and the corresponding scores
results = pd.DataFrame([['Logistic Regression', acc_LR, f1_LR, pre_LR, rec_LR]],
                       columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall'])

# Printing the evaluation results
results

"""Confusion Matrix"""

# Calculating the confusion matrix using the true labels (y_test) and the predicted labels (y_pred)
cm = confusion_matrix(y_test, y_pred)

# Printing the confusion matrix
print(cm)

"""## 2) Random forest"""

# Importing the RandomForestClassifier class from the ensemble module in the sklearn library
from sklearn.ensemble import RandomForestClassifier

# Creating an instance of the RandomForestClassifier with a random_state of 0
# The random_state parameter ensures reproducibility of the randomization process
classifier_Rf = RandomForestClassifier(random_state=0)

# Training the RandomForestClassifier using the training data
# x_train is the input features or independent variables
# y_train is the target variable or dependent variable
classifier_Rf.fit(x_train, y_train)

# Generating predictions using the trained RandomForestClassifier on the test data
# x_test represents the input features of the test data
y_pred = classifier_Rf.predict(x_test)

# Calculating the accuracy score by comparing the true labels (y_test) with the predicted labels (y_pred)
acc_RF = accuracy_score(y_test, y_pred)

# Calculating the F1 score by comparing the true labels (y_test) with the predicted labels (y_pred)
f1_RF = f1_score(y_test, y_pred)

# Calculating the precision score by comparing the true labels (y_test) with the predicted labels (y_pred)
pre_RF = precision_score(y_test, y_pred)

# Calculating the recall score by comparing the true labels (y_test) with the predicted labels (y_pred)
rec_RF = recall_score(y_test, y_pred)

# Creating a new DataFrame to store the evaluation results for the Random Forest model
# The DataFrame has one row containing the model name and the corresponding scores
results_RF = pd.DataFrame([['Random Forest', acc_RF, f1_RF, pre_RF, rec_RF]],
                          columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall'])

# Appending the Random Forest results to the existing results DataFrame
results = results.append(results_RF, ignore_index=True)

# Printing the updated results DataFrame
results

"""Confusion Matrix"""

# Calculating the confusion matrix using the true labels (y_test) and the predicted labels (y_pred)
cm = confusion_matrix(y_test, y_pred)

# Printing the confusion matrix
print(cm)

"""## 3) XGBoost classifier"""

# Importing the XGBClassifier class from the xgboost library
from xgboost import XGBClassifier

# Creating an instance of the XGBClassifier with a random_state of 0
# The random_state parameter ensures reproducibility of the randomization process
classifier_xgb = XGBClassifier(random_state=0)

# Training the XGBClassifier using the training data
# x_train is the input features or independent variables
# y_train is the target variable or dependent variable
classifier_xgb.fit(x_train, y_train)

# Generating predictions using the trained XGBClassifier on the test data
# x_test represents the input features of the test data
y_pred = classifier_xgb.predict(x_test)

# Calculating the accuracy score by comparing the true labels (y_test) with the predicted labels (y_pred)
acc_xgb = accuracy_score(y_test, y_pred)

# Calculating the precision score by comparing the true labels (y_test) with the predicted labels (y_pred)
prec_xgb = precision_score(y_test, y_pred)

# Calculating the recall score by comparing the true labels (y_test) with the predicted labels (y_pred)
rec_xgb = recall_score(y_test, y_pred)

# Calculating the F1 score by comparing the true labels (y_test) with the predicted labels (y_pred)
f1_xgb = f1_score(y_test, y_pred)

# Creating a new DataFrame to store the evaluation results for the XGBoost model
# The DataFrame has one row containing the model name and the corresponding scores
results_xgb = pd.DataFrame([['XGBoost', acc_xgb, prec_xgb, rec_xgb, f1_xgb]],
                             columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])

# Appending the XGBoost results to the existing results DataFrame
results = results.append(results_xgb, ignore_index=True)

# Printing the updated results DataFrame
results

"""Confusion Matrix"""

# Calculating the confusion matrix using the true labels (y_test) and the predicted labels (y_pred)
cm = confusion_matrix(y_test, y_pred)

# Printing the confusion matrix
print(cm)

"""## Determining the max accuracy"""

# Assuming you have the accuracy scores stored in a list called accuracy_scores

# Creating a list of model names
model_names = ["Logistic Regression", "Random Forest", "XGBoost"]
accuracy_scores = [acc_LR, acc_RF, acc_xgb]

# Creating a dictionary to map model names to accuracy scores
model_accuracy_dict = dict(zip(model_names, accuracy_scores))

# Finding the maximum accuracy score using the max() function and retrieving the corresponding model name
max_accuracy_model = max(model_accuracy_dict, key=model_accuracy_dict.get)
max_accuracy = model_accuracy_dict[max_accuracy_model]

# Printing the model name and maximum accuracy
print("Model with Maximum Accuracy: {} - {:.2f}%".format(max_accuracy_model, max_accuracy * 100))



"""# Part 3: Final model (XGBoost)"""

# Importing the XGBClassifier class from the xgboost library
from xgboost import XGBClassifier

# Creating an instance of the XGBClassifier with a random_state of 0
# The random_state parameter ensures reproducibility of the randomization process
classifier = XGBClassifier(random_state=0)

# Training the XGBClassifier using the training data
# x_train is the input features or independent variables
# y_train is the target variable or dependent variable
classifier.fit(x_train, y_train)

# Generating predictions using the trained XGBClassifier on the test data
# x_test represents the input features of the test data
y_pred = classifier.predict(x_test)

# Calculating the accuracy score by comparing the true labels (y_test) with the predicted labels (y_pred)
acc_xgb = accuracy_score(y_test, y_pred)

# Calculating the precision score by comparing the true labels (y_test) with the predicted labels (y_pred)
prec_xgb = precision_score(y_test, y_pred)

# Calculating the recall score by comparing the true labels (y_test) with the predicted labels (y_pred)
rec_xgb = recall_score(y_test, y_pred)

# Calculating the F1 score by comparing the true labels (y_test) with the predicted labels (y_pred)
f1_xgb = f1_score(y_test, y_pred)

# Creating a new DataFrame to store the evaluation results for the XGBoost model
# The DataFrame has one row containing the model name and the corresponding scores
results = pd.DataFrame([['XGBoost', acc_xgb, prec_xgb, rec_xgb, f1_xgb]],
                             columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])

# Printing the updated results DataFrame
results

# Calculating the confusion matrix using the true labels (y_test) and the predicted labels (y_pred)
cm = confusion_matrix(y_test, y_pred)

# Printing the confusion matrix
print(cm)

"""# Part 4: Predicting a single observation"""

dataset.head()

dataset.shape

single_obs = [[0.0, -1.359807,	-0.072781,	2.536347,	1.378155,	-0.338321,	0.462388,	0.239599,	0.098698,	0.363787,	0.090794,	-0.551600,	-0.617801,	-0.991390,	-0.311169,	1.468177,	-0.470401,	0.207971,	0.025791,	0.403993,	0.251412,	-0.018307,	0.277838,	-0.110474,	0.066928,	0.128539,	-0.189115,	0.133558,	-0.021053,	149.62
]]

result = classifier.predict(sc.transform(single_obs))
print(result)

